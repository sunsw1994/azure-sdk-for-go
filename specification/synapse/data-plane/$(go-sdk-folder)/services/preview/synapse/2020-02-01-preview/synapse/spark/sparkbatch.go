package synapse

// Copyright (c) Microsoft and contributors.  All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

import (
    "github.com/Azure/go-autorest/autorest"
    "github.com/Azure/go-autorest/autorest/azure"
    "net/http"
    "context"
    "github.com/Azure/go-autorest/tracing"
    "github.com/Azure/go-autorest/autorest/validation"
)

// SparkBatchClient is the client for the SparkBatch methods of the Synapse service.
type SparkBatchClient struct {
    BaseClient
}
// NewSparkBatchClient creates an instance of the SparkBatchClient client.
func NewSparkBatchClient(endpoint string, sparkPoolName string) SparkBatchClient {
    return SparkBatchClient{ New(endpoint, sparkPoolName)}
}

// CancelSparkBatchJob cancels a running spark batch job.
    // Parameters:
        // batchID - identifier for the batch job.
func (client SparkBatchClient) CancelSparkBatchJob(ctx context.Context, batchID int32) (result autorest.Response, err error) {
    if tracing.IsEnabled() {
        ctx = tracing.StartSpan(ctx, fqdn + "/SparkBatchClient.CancelSparkBatchJob")
        defer func() {
            sc := -1
        if result.Response != nil {
        sc = result.Response.StatusCode
        }
            tracing.EndSpan(ctx, sc, err)
        }()
    }
    req, err := client.CancelSparkBatchJobPreparer(ctx, batchID)
    if err != nil {
    err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "CancelSparkBatchJob", nil , "Failure preparing request")
    return
    }

        resp, err := client.CancelSparkBatchJobSender(req)
        if err != nil {
        result.Response = resp
        err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "CancelSparkBatchJob", resp, "Failure sending request")
        return
        }

        result, err = client.CancelSparkBatchJobResponder(resp)
        if err != nil {
        err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "CancelSparkBatchJob", resp, "Failure responding to request")
        }

    return
}

    // CancelSparkBatchJobPreparer prepares the CancelSparkBatchJob request.
    func (client SparkBatchClient) CancelSparkBatchJobPreparer(ctx context.Context, batchID int32) (*http.Request, error) {
        urlParameters := map[string]interface{} {
        "endpoint": client.Endpoint,
        "livyApiVersion": client.LivyAPIVersion,
        "sparkPoolName": client.SparkPoolName,
        }

        pathParameters := map[string]interface{} {
        "batchId": autorest.Encode("path",batchID),
        }

    preparer := autorest.CreatePreparer(
autorest.AsDelete(),
autorest.WithCustomBaseURL("{endpoint}/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}", urlParameters),
autorest.WithPathParameters("/batches/{batchId}",pathParameters))
    return preparer.Prepare((&http.Request{}).WithContext(ctx))
    }

    // CancelSparkBatchJobSender sends the CancelSparkBatchJob request. The method will close the
    // http.Response Body if it receives an error.
    func (client SparkBatchClient) CancelSparkBatchJobSender(req *http.Request) (*http.Response, error) {
            return client.Send(req, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))
            }

    // CancelSparkBatchJobResponder handles the response to the CancelSparkBatchJob request. The method always
    // closes the http.Response Body.
    func (client SparkBatchClient) CancelSparkBatchJobResponder(resp *http.Response) (result autorest.Response, err error) {
            err = autorest.Respond(
            resp,
            azure.WithErrorUnlessStatusCode(http.StatusOK),
            autorest.ByClosing())
            result.Response = resp
            return
    }

// CreateSparkBatchJob create new spark batch job.
    // Parameters:
        // sparkBatchJobOptions - livy compatible batch job request payload.
        // detailed - optional query param specifying whether detailed response is returned beyond plain livy.
func (client SparkBatchClient) CreateSparkBatchJob(ctx context.Context, sparkBatchJobOptions SparkBatchJobOptions, detailed *bool) (result SparkBatchJob, err error) {
    if tracing.IsEnabled() {
        ctx = tracing.StartSpan(ctx, fqdn + "/SparkBatchClient.CreateSparkBatchJob")
        defer func() {
            sc := -1
        if result.Response.Response != nil {
        sc = result.Response.Response.StatusCode
        }
            tracing.EndSpan(ctx, sc, err)
        }()
    }
        if err := validation.Validate([]validation.Validation{
        { TargetValue: sparkBatchJobOptions,
         Constraints: []validation.Constraint{	{Target: "sparkBatchJobOptions.Name", Name: validation.Null, Rule: true, Chain: nil },
        	{Target: "sparkBatchJobOptions.File", Name: validation.Null, Rule: true, Chain: nil }}}}); err != nil {
        return result, validation.NewError("synapse.SparkBatchClient", "CreateSparkBatchJob", err.Error())
        }

        req, err := client.CreateSparkBatchJobPreparer(ctx, sparkBatchJobOptions, detailed)
    if err != nil {
    err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "CreateSparkBatchJob", nil , "Failure preparing request")
    return
    }

        resp, err := client.CreateSparkBatchJobSender(req)
        if err != nil {
        result.Response = autorest.Response{Response: resp}
        err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "CreateSparkBatchJob", resp, "Failure sending request")
        return
        }

        result, err = client.CreateSparkBatchJobResponder(resp)
        if err != nil {
        err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "CreateSparkBatchJob", resp, "Failure responding to request")
        }

    return
}

    // CreateSparkBatchJobPreparer prepares the CreateSparkBatchJob request.
    func (client SparkBatchClient) CreateSparkBatchJobPreparer(ctx context.Context, sparkBatchJobOptions SparkBatchJobOptions, detailed *bool) (*http.Request, error) {
        urlParameters := map[string]interface{} {
        "endpoint": client.Endpoint,
        "livyApiVersion": client.LivyAPIVersion,
        "sparkPoolName": client.SparkPoolName,
        }

        queryParameters := map[string]interface{} {
    }
        if detailed != nil {
        queryParameters["detailed"] = autorest.Encode("query",*detailed)
        }

    preparer := autorest.CreatePreparer(
autorest.AsContentType("application/json; charset=utf-8"),
autorest.AsPost(),
autorest.WithCustomBaseURL("{endpoint}/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}", urlParameters),
autorest.WithPath("/batches"),
autorest.WithJSON(sparkBatchJobOptions),
autorest.WithQueryParameters(queryParameters))
    return preparer.Prepare((&http.Request{}).WithContext(ctx))
    }

    // CreateSparkBatchJobSender sends the CreateSparkBatchJob request. The method will close the
    // http.Response Body if it receives an error.
    func (client SparkBatchClient) CreateSparkBatchJobSender(req *http.Request) (*http.Response, error) {
            return client.Send(req, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))
            }

    // CreateSparkBatchJobResponder handles the response to the CreateSparkBatchJob request. The method always
    // closes the http.Response Body.
    func (client SparkBatchClient) CreateSparkBatchJobResponder(resp *http.Response) (result SparkBatchJob, err error) {
            err = autorest.Respond(
            resp,
            azure.WithErrorUnlessStatusCode(http.StatusOK),
            autorest.ByUnmarshallingJSON(&result),
            autorest.ByClosing())
            result.Response = autorest.Response{Response: resp}
            return
    }

// GetSparkBatchJob gets a single spark batch job.
    // Parameters:
        // batchID - identifier for the batch job.
        // detailed - optional query param specifying whether detailed response is returned beyond plain livy.
func (client SparkBatchClient) GetSparkBatchJob(ctx context.Context, batchID int32, detailed *bool) (result SparkBatchJob, err error) {
    if tracing.IsEnabled() {
        ctx = tracing.StartSpan(ctx, fqdn + "/SparkBatchClient.GetSparkBatchJob")
        defer func() {
            sc := -1
        if result.Response.Response != nil {
        sc = result.Response.Response.StatusCode
        }
            tracing.EndSpan(ctx, sc, err)
        }()
    }
    req, err := client.GetSparkBatchJobPreparer(ctx, batchID, detailed)
    if err != nil {
    err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "GetSparkBatchJob", nil , "Failure preparing request")
    return
    }

        resp, err := client.GetSparkBatchJobSender(req)
        if err != nil {
        result.Response = autorest.Response{Response: resp}
        err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "GetSparkBatchJob", resp, "Failure sending request")
        return
        }

        result, err = client.GetSparkBatchJobResponder(resp)
        if err != nil {
        err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "GetSparkBatchJob", resp, "Failure responding to request")
        }

    return
}

    // GetSparkBatchJobPreparer prepares the GetSparkBatchJob request.
    func (client SparkBatchClient) GetSparkBatchJobPreparer(ctx context.Context, batchID int32, detailed *bool) (*http.Request, error) {
        urlParameters := map[string]interface{} {
        "endpoint": client.Endpoint,
        "livyApiVersion": client.LivyAPIVersion,
        "sparkPoolName": client.SparkPoolName,
        }

        pathParameters := map[string]interface{} {
        "batchId": autorest.Encode("path",batchID),
        }

        queryParameters := map[string]interface{} {
    }
        if detailed != nil {
        queryParameters["detailed"] = autorest.Encode("query",*detailed)
        }

    preparer := autorest.CreatePreparer(
autorest.AsGet(),
autorest.WithCustomBaseURL("{endpoint}/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}", urlParameters),
autorest.WithPathParameters("/batches/{batchId}",pathParameters),
autorest.WithQueryParameters(queryParameters))
    return preparer.Prepare((&http.Request{}).WithContext(ctx))
    }

    // GetSparkBatchJobSender sends the GetSparkBatchJob request. The method will close the
    // http.Response Body if it receives an error.
    func (client SparkBatchClient) GetSparkBatchJobSender(req *http.Request) (*http.Response, error) {
            return client.Send(req, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))
            }

    // GetSparkBatchJobResponder handles the response to the GetSparkBatchJob request. The method always
    // closes the http.Response Body.
    func (client SparkBatchClient) GetSparkBatchJobResponder(resp *http.Response) (result SparkBatchJob, err error) {
            err = autorest.Respond(
            resp,
            azure.WithErrorUnlessStatusCode(http.StatusOK),
            autorest.ByUnmarshallingJSON(&result),
            autorest.ByClosing())
            result.Response = autorest.Response{Response: resp}
            return
    }

// GetSparkBatchJobs list all spark batch jobs which are running under a particular spark pool.
    // Parameters:
        // from - optional param specifying which index the list should begin from.
        // size - optional param specifying the size of the returned list.
        // By default it is 20 and that is the maximum.
        // detailed - optional query param specifying whether detailed response is returned beyond plain livy.
func (client SparkBatchClient) GetSparkBatchJobs(ctx context.Context, from *int32, size *int32, detailed *bool) (result SparkBatchJobCollection, err error) {
    if tracing.IsEnabled() {
        ctx = tracing.StartSpan(ctx, fqdn + "/SparkBatchClient.GetSparkBatchJobs")
        defer func() {
            sc := -1
        if result.Response.Response != nil {
        sc = result.Response.Response.StatusCode
        }
            tracing.EndSpan(ctx, sc, err)
        }()
    }
    req, err := client.GetSparkBatchJobsPreparer(ctx, from, size, detailed)
    if err != nil {
    err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "GetSparkBatchJobs", nil , "Failure preparing request")
    return
    }

        resp, err := client.GetSparkBatchJobsSender(req)
        if err != nil {
        result.Response = autorest.Response{Response: resp}
        err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "GetSparkBatchJobs", resp, "Failure sending request")
        return
        }

        result, err = client.GetSparkBatchJobsResponder(resp)
        if err != nil {
        err = autorest.NewErrorWithError(err, "synapse.SparkBatchClient", "GetSparkBatchJobs", resp, "Failure responding to request")
        }

    return
}

    // GetSparkBatchJobsPreparer prepares the GetSparkBatchJobs request.
    func (client SparkBatchClient) GetSparkBatchJobsPreparer(ctx context.Context, from *int32, size *int32, detailed *bool) (*http.Request, error) {
        urlParameters := map[string]interface{} {
        "endpoint": client.Endpoint,
        "livyApiVersion": client.LivyAPIVersion,
        "sparkPoolName": client.SparkPoolName,
        }

        queryParameters := map[string]interface{} {
    }
        if from != nil {
        queryParameters["from"] = autorest.Encode("query",*from)
        }
        if size != nil {
        queryParameters["size"] = autorest.Encode("query",*size)
        }
        if detailed != nil {
        queryParameters["detailed"] = autorest.Encode("query",*detailed)
        }

    preparer := autorest.CreatePreparer(
autorest.AsGet(),
autorest.WithCustomBaseURL("{endpoint}/livyApi/versions/{livyApiVersion}/sparkPools/{sparkPoolName}", urlParameters),
autorest.WithPath("/batches"),
autorest.WithQueryParameters(queryParameters))
    return preparer.Prepare((&http.Request{}).WithContext(ctx))
    }

    // GetSparkBatchJobsSender sends the GetSparkBatchJobs request. The method will close the
    // http.Response Body if it receives an error.
    func (client SparkBatchClient) GetSparkBatchJobsSender(req *http.Request) (*http.Response, error) {
            return client.Send(req, autorest.DoRetryForStatusCodes(client.RetryAttempts, client.RetryDuration, autorest.StatusCodesForRetry...))
            }

    // GetSparkBatchJobsResponder handles the response to the GetSparkBatchJobs request. The method always
    // closes the http.Response Body.
    func (client SparkBatchClient) GetSparkBatchJobsResponder(resp *http.Response) (result SparkBatchJobCollection, err error) {
            err = autorest.Respond(
            resp,
            azure.WithErrorUnlessStatusCode(http.StatusOK),
            autorest.ByUnmarshallingJSON(&result),
            autorest.ByClosing())
            result.Response = autorest.Response{Response: resp}
            return
    }

