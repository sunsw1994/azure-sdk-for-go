package synapse

// Copyright (c) Microsoft and contributors.  All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

import (
    "encoding/json"
    "github.com/Azure/go-autorest/autorest"
    "github.com/Azure/go-autorest/autorest/date"
)

// The package's fully qualified name.
const fqdn = "$(go-sdk-folder)/services/preview/synapse/2020-02-01-preview/synapse/spark"

        // SparkBatchJob ...
        type SparkBatchJob struct {
        autorest.Response `json:"-"`
        LivyInfo *SparkBatchJobState `json:"livyInfo,omitempty"`
        // Name - The batch name.
        Name *string `json:"name,omitempty"`
        // WorkspaceName - The workspace name.
        WorkspaceName *string `json:"workspaceName,omitempty"`
        // SparkPoolName - The Spark pool name.
        SparkPoolName *string `json:"sparkPoolName,omitempty"`
        // SubmitterName - The submitter name.
        SubmitterName *string `json:"submitterName,omitempty"`
        // SubmitterID - The submitter identifier.
        SubmitterID *string `json:"submitterId,omitempty"`
        // ArtifactID - The artifact identifier.
        ArtifactID *string `json:"artifactId,omitempty"`
        // JobType - The job type. Possible values include: 'SparkJobTypeSparkBatch', 'SparkJobTypeSparkSession'
        JobType SparkJobType `json:"jobType,omitempty"`
        // Result - The Spark batch job result. Possible values include: 'Uncertain', 'Succeeded', 'Failed', 'Cancelled'
        Result SparkBatchJobResultType `json:"result,omitempty"`
        // Scheduler - The scheduler information.
        Scheduler *SparkScheduler `json:"schedulerInfo,omitempty"`
        // Plugin - The plugin information.
        Plugin *SparkServicePlugin `json:"pluginInfo,omitempty"`
        // Errors - The error information.
        Errors *[]SparkServiceError `json:"errorInfo,omitempty"`
        // Tags - The tags.
        Tags map[string]*string `json:"tags"`
        // ID - The session Id.
        ID *int32 `json:"id,omitempty"`
        // AppID - The application id of this session
        AppID *string `json:"appId,omitempty"`
        // AppInfo - The detailed application info.
        AppInfo map[string]*string `json:"appInfo"`
        // State - The batch state
        State *string `json:"state,omitempty"`
        // LogLines - The log lines.
        LogLines *[]string `json:"log,omitempty"`
        }

        // MarshalJSON is the custom marshaler for SparkBatchJob.
        func (sbj SparkBatchJob)MarshalJSON() ([]byte, error){
        objectMap := make(map[string]interface{})
                if(sbj.LivyInfo != nil) {
                objectMap["livyInfo"] = sbj.LivyInfo
                }
                if(sbj.Name != nil) {
                objectMap["name"] = sbj.Name
                }
                if(sbj.WorkspaceName != nil) {
                objectMap["workspaceName"] = sbj.WorkspaceName
                }
                if(sbj.SparkPoolName != nil) {
                objectMap["sparkPoolName"] = sbj.SparkPoolName
                }
                if(sbj.SubmitterName != nil) {
                objectMap["submitterName"] = sbj.SubmitterName
                }
                if(sbj.SubmitterID != nil) {
                objectMap["submitterId"] = sbj.SubmitterID
                }
                if(sbj.ArtifactID != nil) {
                objectMap["artifactId"] = sbj.ArtifactID
                }
                if(sbj.JobType != "") {
                objectMap["jobType"] = sbj.JobType
                }
                if(sbj.Result != "") {
                objectMap["result"] = sbj.Result
                }
                if(sbj.Scheduler != nil) {
                objectMap["schedulerInfo"] = sbj.Scheduler
                }
                if(sbj.Plugin != nil) {
                objectMap["pluginInfo"] = sbj.Plugin
                }
                if(sbj.Errors != nil) {
                objectMap["errorInfo"] = sbj.Errors
                }
                if(sbj.Tags != nil) {
                objectMap["tags"] = sbj.Tags
                }
                if(sbj.ID != nil) {
                objectMap["id"] = sbj.ID
                }
                if(sbj.AppID != nil) {
                objectMap["appId"] = sbj.AppID
                }
                if(sbj.AppInfo != nil) {
                objectMap["appInfo"] = sbj.AppInfo
                }
                if(sbj.State != nil) {
                objectMap["state"] = sbj.State
                }
                if(sbj.LogLines != nil) {
                objectMap["log"] = sbj.LogLines
                }
                return json.Marshal(objectMap)
        }

        // SparkBatchJobCollection response for batch list operation.
        type SparkBatchJobCollection struct {
        autorest.Response `json:"-"`
        // From - The start index of fetched sessions.
        From *int32 `json:"from,omitempty"`
        // Total - Number of sessions fetched.
        Total *int32 `json:"total,omitempty"`
        // Sessions - Batch list
        Sessions *[]SparkBatchJob `json:"sessions,omitempty"`
        }

        // SparkBatchJobOptions ...
        type SparkBatchJobOptions struct {
        Tags map[string]*string `json:"tags"`
        ArtifactID *string `json:"artifactId,omitempty"`
        Name *string `json:"name,omitempty"`
        File *string `json:"file,omitempty"`
        ClassName *string `json:"className,omitempty"`
        Arguments *[]string `json:"args,omitempty"`
        Jars *[]string `json:"jars,omitempty"`
        PythonFiles *[]string `json:"pyFiles,omitempty"`
        Files *[]string `json:"files,omitempty"`
        Archives *[]string `json:"archives,omitempty"`
        Configuration map[string]*string `json:"conf"`
        DriverMemory *string `json:"driverMemory,omitempty"`
        DriverCores *int32 `json:"driverCores,omitempty"`
        ExecutorMemory *string `json:"executorMemory,omitempty"`
        ExecutorCores *int32 `json:"executorCores,omitempty"`
        ExecutorCount *int32 `json:"numExecutors,omitempty"`
        }

        // MarshalJSON is the custom marshaler for SparkBatchJobOptions.
        func (sbjo SparkBatchJobOptions)MarshalJSON() ([]byte, error){
        objectMap := make(map[string]interface{})
                if(sbjo.Tags != nil) {
                objectMap["tags"] = sbjo.Tags
                }
                if(sbjo.ArtifactID != nil) {
                objectMap["artifactId"] = sbjo.ArtifactID
                }
                if(sbjo.Name != nil) {
                objectMap["name"] = sbjo.Name
                }
                if(sbjo.File != nil) {
                objectMap["file"] = sbjo.File
                }
                if(sbjo.ClassName != nil) {
                objectMap["className"] = sbjo.ClassName
                }
                if(sbjo.Arguments != nil) {
                objectMap["args"] = sbjo.Arguments
                }
                if(sbjo.Jars != nil) {
                objectMap["jars"] = sbjo.Jars
                }
                if(sbjo.PythonFiles != nil) {
                objectMap["pyFiles"] = sbjo.PythonFiles
                }
                if(sbjo.Files != nil) {
                objectMap["files"] = sbjo.Files
                }
                if(sbjo.Archives != nil) {
                objectMap["archives"] = sbjo.Archives
                }
                if(sbjo.Configuration != nil) {
                objectMap["conf"] = sbjo.Configuration
                }
                if(sbjo.DriverMemory != nil) {
                objectMap["driverMemory"] = sbjo.DriverMemory
                }
                if(sbjo.DriverCores != nil) {
                objectMap["driverCores"] = sbjo.DriverCores
                }
                if(sbjo.ExecutorMemory != nil) {
                objectMap["executorMemory"] = sbjo.ExecutorMemory
                }
                if(sbjo.ExecutorCores != nil) {
                objectMap["executorCores"] = sbjo.ExecutorCores
                }
                if(sbjo.ExecutorCount != nil) {
                objectMap["numExecutors"] = sbjo.ExecutorCount
                }
                return json.Marshal(objectMap)
        }

        // SparkBatchJobState ...
        type SparkBatchJobState struct {
        // NotStartedAt - the time that at which "not_started" livy state was first seen.
        NotStartedAt *date.Time `json:"notStartedAt,omitempty"`
        // StartingAt - the time that at which "starting" livy state was first seen.
        StartingAt *date.Time `json:"startingAt,omitempty"`
        // RunningAt - the time that at which "running" livy state was first seen.
        RunningAt *date.Time `json:"runningAt,omitempty"`
        // DeadAt - time that at which "dead" livy state was first seen.
        DeadAt *date.Time `json:"deadAt,omitempty"`
        // SuccessAt - the time that at which "success" livy state was first seen.
        SuccessAt *date.Time `json:"successAt,omitempty"`
        // TerminatedAt - the time that at which "killed" livy state was first seen.
        TerminatedAt *date.Time `json:"killedAt,omitempty"`
        // RecoveringAt - the time that at which "recovering" livy state was first seen.
        RecoveringAt *date.Time `json:"recoveringAt,omitempty"`
        // CurrentState - the Spark job state.
        CurrentState *string `json:"currentState,omitempty"`
        JobCreationRequest *SparkRequest `json:"jobCreationRequest,omitempty"`
        }

        // SparkRequest ...
        type SparkRequest struct {
        Name *string `json:"name,omitempty"`
        File *string `json:"file,omitempty"`
        ClassName *string `json:"className,omitempty"`
        Arguments *[]string `json:"args,omitempty"`
        Jars *[]string `json:"jars,omitempty"`
        PythonFiles *[]string `json:"pyFiles,omitempty"`
        Files *[]string `json:"files,omitempty"`
        Archives *[]string `json:"archives,omitempty"`
        Configuration map[string]*string `json:"conf"`
        DriverMemory *string `json:"driverMemory,omitempty"`
        DriverCores *int32 `json:"driverCores,omitempty"`
        ExecutorMemory *string `json:"executorMemory,omitempty"`
        ExecutorCores *int32 `json:"executorCores,omitempty"`
        ExecutorCount *int32 `json:"numExecutors,omitempty"`
        }

        // MarshalJSON is the custom marshaler for SparkRequest.
        func (sr SparkRequest)MarshalJSON() ([]byte, error){
        objectMap := make(map[string]interface{})
                if(sr.Name != nil) {
                objectMap["name"] = sr.Name
                }
                if(sr.File != nil) {
                objectMap["file"] = sr.File
                }
                if(sr.ClassName != nil) {
                objectMap["className"] = sr.ClassName
                }
                if(sr.Arguments != nil) {
                objectMap["args"] = sr.Arguments
                }
                if(sr.Jars != nil) {
                objectMap["jars"] = sr.Jars
                }
                if(sr.PythonFiles != nil) {
                objectMap["pyFiles"] = sr.PythonFiles
                }
                if(sr.Files != nil) {
                objectMap["files"] = sr.Files
                }
                if(sr.Archives != nil) {
                objectMap["archives"] = sr.Archives
                }
                if(sr.Configuration != nil) {
                objectMap["conf"] = sr.Configuration
                }
                if(sr.DriverMemory != nil) {
                objectMap["driverMemory"] = sr.DriverMemory
                }
                if(sr.DriverCores != nil) {
                objectMap["driverCores"] = sr.DriverCores
                }
                if(sr.ExecutorMemory != nil) {
                objectMap["executorMemory"] = sr.ExecutorMemory
                }
                if(sr.ExecutorCores != nil) {
                objectMap["executorCores"] = sr.ExecutorCores
                }
                if(sr.ExecutorCount != nil) {
                objectMap["numExecutors"] = sr.ExecutorCount
                }
                return json.Marshal(objectMap)
        }

        // SparkScheduler ...
        type SparkScheduler struct {
        SubmittedAt *date.Time `json:"submittedAt,omitempty"`
        ScheduledAt *date.Time `json:"scheduledAt,omitempty"`
        EndedAt *date.Time `json:"endedAt,omitempty"`
        CancellationRequestedAt *date.Time `json:"cancellationRequestedAt,omitempty"`
        // CurrentState - Possible values include: 'SchedulerCurrentStateQueued', 'SchedulerCurrentStateScheduled', 'SchedulerCurrentStateEnded'
        CurrentState SchedulerCurrentState `json:"currentState,omitempty"`
        }

        // SparkServiceError ...
        type SparkServiceError struct {
        Message *string `json:"message,omitempty"`
        ErrorCode *string `json:"errorCode,omitempty"`
        // Source - Possible values include: 'System', 'User', 'Unknown', 'Dependency'
        Source SparkErrorSource `json:"source,omitempty"`
        }

        // SparkServicePlugin ...
        type SparkServicePlugin struct {
        PreparationStartedAt *date.Time `json:"preparationStartedAt,omitempty"`
        ResourceAcquisitionStartedAt *date.Time `json:"resourceAcquisitionStartedAt,omitempty"`
        SubmissionStartedAt *date.Time `json:"submissionStartedAt,omitempty"`
        MonitoringStartedAt *date.Time `json:"monitoringStartedAt,omitempty"`
        CleanupStartedAt *date.Time `json:"cleanupStartedAt,omitempty"`
        // CurrentState - Possible values include: 'Preparation', 'ResourceAcquisition', 'Queued', 'Submission', 'Monitoring', 'Cleanup', 'Ended'
        CurrentState PluginCurrentState `json:"currentState,omitempty"`
        }

        // SparkSession ...
        type SparkSession struct {
        autorest.Response `json:"-"`
        LivyInfo *SparkSessionState `json:"livyInfo,omitempty"`
        Name *string `json:"name,omitempty"`
        WorkspaceName *string `json:"workspaceName,omitempty"`
        SparkPoolName *string `json:"sparkPoolName,omitempty"`
        SubmitterName *string `json:"submitterName,omitempty"`
        SubmitterID *string `json:"submitterId,omitempty"`
        ArtifactID *string `json:"artifactId,omitempty"`
        // JobType - Possible values include: 'SparkJobTypeSparkBatch', 'SparkJobTypeSparkSession'
        JobType SparkJobType `json:"jobType,omitempty"`
        // Result - Possible values include: 'SparkSessionResultTypeUncertain', 'SparkSessionResultTypeSucceeded', 'SparkSessionResultTypeFailed', 'SparkSessionResultTypeCancelled'
        Result SparkSessionResultType `json:"result,omitempty"`
        Scheduler *SparkScheduler `json:"schedulerInfo,omitempty"`
        Plugin *SparkServicePlugin `json:"pluginInfo,omitempty"`
        Errors *[]SparkServiceError `json:"errorInfo,omitempty"`
        Tags map[string]*string `json:"tags"`
        ID *int32 `json:"id,omitempty"`
        AppID *string `json:"appId,omitempty"`
        AppInfo map[string]*string `json:"appInfo"`
        State *string `json:"state,omitempty"`
        LogLines *[]string `json:"log,omitempty"`
        }

        // MarshalJSON is the custom marshaler for SparkSession.
        func (ss SparkSession)MarshalJSON() ([]byte, error){
        objectMap := make(map[string]interface{})
                if(ss.LivyInfo != nil) {
                objectMap["livyInfo"] = ss.LivyInfo
                }
                if(ss.Name != nil) {
                objectMap["name"] = ss.Name
                }
                if(ss.WorkspaceName != nil) {
                objectMap["workspaceName"] = ss.WorkspaceName
                }
                if(ss.SparkPoolName != nil) {
                objectMap["sparkPoolName"] = ss.SparkPoolName
                }
                if(ss.SubmitterName != nil) {
                objectMap["submitterName"] = ss.SubmitterName
                }
                if(ss.SubmitterID != nil) {
                objectMap["submitterId"] = ss.SubmitterID
                }
                if(ss.ArtifactID != nil) {
                objectMap["artifactId"] = ss.ArtifactID
                }
                if(ss.JobType != "") {
                objectMap["jobType"] = ss.JobType
                }
                if(ss.Result != "") {
                objectMap["result"] = ss.Result
                }
                if(ss.Scheduler != nil) {
                objectMap["schedulerInfo"] = ss.Scheduler
                }
                if(ss.Plugin != nil) {
                objectMap["pluginInfo"] = ss.Plugin
                }
                if(ss.Errors != nil) {
                objectMap["errorInfo"] = ss.Errors
                }
                if(ss.Tags != nil) {
                objectMap["tags"] = ss.Tags
                }
                if(ss.ID != nil) {
                objectMap["id"] = ss.ID
                }
                if(ss.AppID != nil) {
                objectMap["appId"] = ss.AppID
                }
                if(ss.AppInfo != nil) {
                objectMap["appInfo"] = ss.AppInfo
                }
                if(ss.State != nil) {
                objectMap["state"] = ss.State
                }
                if(ss.LogLines != nil) {
                objectMap["log"] = ss.LogLines
                }
                return json.Marshal(objectMap)
        }

        // SparkSessionCollection ...
        type SparkSessionCollection struct {
        autorest.Response `json:"-"`
        From *int32 `json:"from,omitempty"`
        Total *int32 `json:"total,omitempty"`
        Sessions *[]SparkSession `json:"sessions,omitempty"`
        }

        // SparkSessionOptions ...
        type SparkSessionOptions struct {
        Tags map[string]*string `json:"tags"`
        ArtifactID *string `json:"artifactId,omitempty"`
        Name *string `json:"name,omitempty"`
        File *string `json:"file,omitempty"`
        ClassName *string `json:"className,omitempty"`
        Arguments *[]string `json:"args,omitempty"`
        Jars *[]string `json:"jars,omitempty"`
        PythonFiles *[]string `json:"pyFiles,omitempty"`
        Files *[]string `json:"files,omitempty"`
        Archives *[]string `json:"archives,omitempty"`
        Configuration map[string]*string `json:"conf"`
        DriverMemory *string `json:"driverMemory,omitempty"`
        DriverCores *int32 `json:"driverCores,omitempty"`
        ExecutorMemory *string `json:"executorMemory,omitempty"`
        ExecutorCores *int32 `json:"executorCores,omitempty"`
        ExecutorCount *int32 `json:"numExecutors,omitempty"`
        }

        // MarshalJSON is the custom marshaler for SparkSessionOptions.
        func (sso SparkSessionOptions)MarshalJSON() ([]byte, error){
        objectMap := make(map[string]interface{})
                if(sso.Tags != nil) {
                objectMap["tags"] = sso.Tags
                }
                if(sso.ArtifactID != nil) {
                objectMap["artifactId"] = sso.ArtifactID
                }
                if(sso.Name != nil) {
                objectMap["name"] = sso.Name
                }
                if(sso.File != nil) {
                objectMap["file"] = sso.File
                }
                if(sso.ClassName != nil) {
                objectMap["className"] = sso.ClassName
                }
                if(sso.Arguments != nil) {
                objectMap["args"] = sso.Arguments
                }
                if(sso.Jars != nil) {
                objectMap["jars"] = sso.Jars
                }
                if(sso.PythonFiles != nil) {
                objectMap["pyFiles"] = sso.PythonFiles
                }
                if(sso.Files != nil) {
                objectMap["files"] = sso.Files
                }
                if(sso.Archives != nil) {
                objectMap["archives"] = sso.Archives
                }
                if(sso.Configuration != nil) {
                objectMap["conf"] = sso.Configuration
                }
                if(sso.DriverMemory != nil) {
                objectMap["driverMemory"] = sso.DriverMemory
                }
                if(sso.DriverCores != nil) {
                objectMap["driverCores"] = sso.DriverCores
                }
                if(sso.ExecutorMemory != nil) {
                objectMap["executorMemory"] = sso.ExecutorMemory
                }
                if(sso.ExecutorCores != nil) {
                objectMap["executorCores"] = sso.ExecutorCores
                }
                if(sso.ExecutorCount != nil) {
                objectMap["numExecutors"] = sso.ExecutorCount
                }
                return json.Marshal(objectMap)
        }

        // SparkSessionState ...
        type SparkSessionState struct {
        NotStartedAt *date.Time `json:"notStartedAt,omitempty"`
        StartingAt *date.Time `json:"startingAt,omitempty"`
        IdleAt *date.Time `json:"idleAt,omitempty"`
        DeadAt *date.Time `json:"deadAt,omitempty"`
        ShuttingDownAt *date.Time `json:"shuttingDownAt,omitempty"`
        TerminatedAt *date.Time `json:"killedAt,omitempty"`
        RecoveringAt *date.Time `json:"recoveringAt,omitempty"`
        BusyAt *date.Time `json:"busyAt,omitempty"`
        ErrorAt *date.Time `json:"errorAt,omitempty"`
        CurrentState *string `json:"currentState,omitempty"`
        JobCreationRequest *SparkRequest `json:"jobCreationRequest,omitempty"`
        }

        // SparkStatement ...
        type SparkStatement struct {
        autorest.Response `json:"-"`
        ID *int32 `json:"id,omitempty"`
        Code *string `json:"code,omitempty"`
        State *string `json:"state,omitempty"`
        Output *SparkStatementOutput `json:"output,omitempty"`
        }

        // SparkStatementCancellationResult ...
        type SparkStatementCancellationResult struct {
        autorest.Response `json:"-"`
        Msg *string `json:"msg,omitempty"`
        }

        // SparkStatementCollection ...
        type SparkStatementCollection struct {
        autorest.Response `json:"-"`
        Total *int32 `json:"total_statements,omitempty"`
        Statements *[]SparkStatement `json:"statements,omitempty"`
        }

        // SparkStatementOptions ...
        type SparkStatementOptions struct {
        Code *string `json:"code,omitempty"`
        // Kind - Possible values include: 'Spark', 'Pyspark', 'Dotnetspark', 'SQL'
        Kind SparkStatementLanguageType `json:"kind,omitempty"`
        }

        // SparkStatementOutput ...
        type SparkStatementOutput struct {
        Status *string `json:"status,omitempty"`
        ExecutionCount *int32 `json:"execution_count,omitempty"`
        Data interface{} `json:"data,omitempty"`
        ErrorName *string `json:"ename,omitempty"`
        ErrorValue *string `json:"evalue,omitempty"`
        Traceback *[]string `json:"traceback,omitempty"`
        }

